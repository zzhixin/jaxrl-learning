wandb: Currently logged in as: zhixin to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run 9ckcqdur
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /home/zhixin/jaxrl-learning/wandb/run-20260108_205046-9ckcqdur
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run Ant-brax__ddpg__0__20260108_205045
wandb: â­ï¸ View project at https://wandb.ai/zhixin/jaxrl
wandb: ğŸš€ View run at https://wandb.ai/zhixin/jaxrl/runs/9ckcqdur
Warp DeprecationWarning: The namespace `warp.context` will soon be removed from the public API. It can still be accessed from `warp._src.context` but might be changed or removed without notice.
Warp DeprecationWarning: The symbol `warp.context.Module` will soon be removed from the public API. Use `warp.Module` instead.
Warp DeprecationWarning: The symbol `warp.context.assert_conditional_graph_support` will soon be removed from the public API. It can still be accessed from `warp._src.context.assert_conditional_graph_support` but might be changed or removed without notice.
Warp DeprecationWarning: The symbol `warp.context.get_module` will soon be removed from the public API. Use `warp.get_module` instead.
Warp DeprecationWarning: The namespace `warp.math` will soon be removed from the public API. It can still be accessed from `warp._src.math` but might be changed or removed without notice.
config:
DDPGConfig(seed=0,
           exp_name='ddpg',
           project_name='jaxrl',
           env_name='Ant-brax',
           norm_obs=True,
           total_timesteps=50000000,
           features=(128, 64),
           lr_critic=0.001,
           lr_actor=0.001,
           gamma=0.99,
           tau=0.001,
           target_update_interval=1,
           exploration_type='normal_noise',
           exploration_noise=0.02,
           exploration_noise_end=0.0,
           exploration_noise_decay=False,
           ou_theta=0.15,
           epsilon_start=1.0,
           epsilon_end=0.05,
           exploration_fraction=0.9,
           num_env=1024,
           train_interval=1024,
           train_batch_size=256,
           buffer_size=1000000.0,
           learning_start=100000.0,
           eval_interval=262144,
           eval_num_steps=2000,
           eval_num_env=1024,
           log_interval=262144,
           wandb=True,
           save_model=True,
           run_name='Ant-brax__ddpg__0__20260108_205045',
           ckpt_path='/home/zhixin/jaxrl-learning/ckpts/',
           silent=False,
           vmap_run=False)
start training...
global_steps: 262144,  episode_return: -71.03484344482422
best_model saved.
global_steps: 524288,  episode_return: -403.3342590332031
global_steps: 786432,  episode_return: -8.129884719848633
best_model saved.
global_steps: 1048576,  episode_return: -7.917943477630615
best_model saved.
global_steps: 1310720,  episode_return: -12.370854377746582
global_steps: 1572864,  episode_return: -2.152130126953125
best_model saved.
global_steps: 1835008,  episode_return: -23.453990936279297
global_steps: 2097152,  episode_return: -45.310752868652344
global_steps: 2359296,  episode_return: 28.566200256347656
best_model saved.
global_steps: 2621440,  episode_return: 227.32479858398438
best_model saved.
global_steps: 2883584,  episode_return: -78.13652801513672
global_steps: 3145728,  episode_return: -231.42477416992188
global_steps: 3407872,  episode_return: -158.8133087158203
global_steps: 3670016,  episode_return: 5.680892467498779
global_steps: 3932160,  episode_return: -63.4450569152832
global_steps: 4194304,  episode_return: -218.82827758789062
global_steps: 4456448,  episode_return: -392.32696533203125
global_steps: 4718592,  episode_return: -83.23043060302734
global_steps: 4980736,  episode_return: -381.2105712890625
global_steps: 5242880,  episode_return: -254.38804626464844
global_steps: 5505024,  episode_return: -353.4753723144531
global_steps: 5767168,  episode_return: -305.0192565917969
global_steps: 6029312,  episode_return: -203.07220458984375
global_steps: 6291456,  episode_return: -157.1484375
global_steps: 6553600,  episode_return: -46.54288864135742
global_steps: 6815744,  episode_return: -58.04032516479492
global_steps: 7077888,  episode_return: -65.20372772216797
global_steps: 7340032,  episode_return: -48.490997314453125
global_steps: 7602176,  episode_return: -26.693214416503906
global_steps: 7864320,  episode_return: -121.24152374267578
global_steps: 8126464,  episode_return: -124.8802719116211
global_steps: 8388608,  episode_return: -76.26443481445312
global_steps: 8650752,  episode_return: -103.58052825927734
global_steps: 8912896,  episode_return: -45.3365478515625
global_steps: 9175040,  episode_return: -42.74338150024414
global_steps: 9437184,  episode_return: -28.154747009277344
global_steps: 9699328,  episode_return: -70.0958480834961
global_steps: 9961472,  episode_return: -77.70344543457031
global_steps: 10223616,  episode_return: -46.71490478515625
global_steps: 10485760,  episode_return: -46.43696212768555
global_steps: 10747904,  episode_return: -62.5715217590332
global_steps: 11010048,  episode_return: -36.778968811035156
global_steps: 11272192,  episode_return: -48.07151412963867
global_steps: 11534336,  episode_return: -55.59304428100586
global_steps: 11796480,  episode_return: -57.042015075683594
global_steps: 12058624,  episode_return: -54.45638656616211
global_steps: 12320768,  episode_return: -35.06159591674805
global_steps: 12582912,  episode_return: -33.57429885864258
global_steps: 12845056,  episode_return: -45.23889923095703
global_steps: 13107200,  episode_return: -66.94695281982422
global_steps: 13369344,  episode_return: -61.419132232666016
global_steps: 13631488,  episode_return: -55.656166076660156
global_steps: 13893632,  episode_return: -75.30013275146484
global_steps: 14155776,  episode_return: -54.99481964111328
global_steps: 14417920,  episode_return: -48.18284225463867
global_steps: 14680064,  episode_return: -57.18950271606445
global_steps: 14942208,  episode_return: -78.41615295410156
global_steps: 15204352,  episode_return: -33.9640998840332
global_steps: 15466496,  episode_return: -40.105289459228516
global_steps: 15728640,  episode_return: -62.38967514038086
global_steps: 15990784,  episode_return: -79.58497619628906
global_steps: 16252928,  episode_return: -44.61625671386719
global_steps: 16515072,  episode_return: -56.84748077392578
global_steps: 16777216,  episode_return: -42.43594741821289
global_steps: 17039360,  episode_return: -29.2281494140625
global_steps: 17301504,  episode_return: -73.20419311523438
global_steps: 17563648,  episode_return: -49.91050720214844
global_steps: 17825792,  episode_return: -42.37184143066406
global_steps: 18087936,  episode_return: -69.93234252929688
global_steps: 18350080,  episode_return: -81.0660171508789
global_steps: 18612224,  episode_return: -122.83394622802734
global_steps: 18874368,  episode_return: -189.53872680664062
global_steps: 19136512,  episode_return: -153.9104461669922
global_steps: 19398656,  episode_return: -146.97055053710938
global_steps: 19660800,  episode_return: -198.87022399902344
global_steps: 19922944,  episode_return: -342.9586486816406
global_steps: 20185088,  episode_return: -131.7555694580078
global_steps: 20447232,  episode_return: -326.24066162109375
global_steps: 20709376,  episode_return: -471.4494934082031
global_steps: 20971520,  episode_return: -373.3023986816406
global_steps: 21233664,  episode_return: -371.0961608886719
global_steps: 21495808,  episode_return: -233.73146057128906
global_steps: 21757952,  episode_return: -364.27978515625
global_steps: 22020096,  episode_return: -213.6238250732422
global_steps: 22282240,  episode_return: -182.1903839111328
global_steps: 22544384,  episode_return: -200.83963012695312
global_steps: 22806528,  episode_return: -215.03636169433594
global_steps: 23068672,  episode_return: -241.5245819091797
global_steps: 23330816,  episode_return: -159.59225463867188
global_steps: 23592960,  episode_return: -207.08164978027344
global_steps: 23855104,  episode_return: -179.70481872558594
global_steps: 24117248,  episode_return: -185.43466186523438
global_steps: 24379392,  episode_return: -191.31689453125
global_steps: 24641536,  episode_return: -169.44021606445312
global_steps: 24903680,  episode_return: -170.9403076171875
global_steps: 25165824,  episode_return: -133.29774475097656
global_steps: 25427968,  episode_return: -174.06593322753906
global_steps: 25690112,  episode_return: -161.24258422851562
global_steps: 25952256,  episode_return: -137.2852783203125
global_steps: 26214400,  episode_return: -141.032470703125
global_steps: 26476544,  episode_return: -157.6001434326172
global_steps: 26738688,  episode_return: -127.97222137451172
global_steps: 27000832,  episode_return: -166.4321746826172
global_steps: 27262976,  episode_return: -143.05178833007812
global_steps: 27525120,  episode_return: -154.96595764160156
global_steps: 27787264,  episode_return: -195.12966918945312
global_steps: 28049408,  episode_return: -135.20590209960938
global_steps: 28311552,  episode_return: -138.427001953125
global_steps: 28573696,  episode_return: -151.87156677246094
global_steps: 28835840,  episode_return: -133.91921997070312
global_steps: 29097984,  episode_return: -153.18695068359375
global_steps: 29360128,  episode_return: -132.38755798339844
global_steps: 29622272,  episode_return: -124.63484954833984
global_steps: 29884416,  episode_return: -136.77822875976562
global_steps: 30146560,  episode_return: -151.73251342773438
global_steps: 30408704,  episode_return: -132.21792602539062
global_steps: 30670848,  episode_return: -117.9091567993164
global_steps: 30932992,  episode_return: -147.17269897460938
global_steps: 31195136,  episode_return: -158.20257568359375
global_steps: 31457280,  episode_return: -128.810791015625
global_steps: 31719424,  episode_return: -86.2448501586914
global_steps: 31981568,  episode_return: -102.73419189453125
global_steps: 32243712,  episode_return: -111.939453125
global_steps: 32505856,  episode_return: -116.85479736328125
global_steps: 32768000,  episode_return: -113.23603057861328
global_steps: 33030144,  episode_return: -84.66719055175781
global_steps: 33292288,  episode_return: -150.7434844970703
global_steps: 33554432,  episode_return: -145.6513671875
global_steps: 33816576,  episode_return: -124.7710189819336
global_steps: 34078720,  episode_return: -143.75035095214844
global_steps: 34340864,  episode_return: -142.2119598388672
global_steps: 34603008,  episode_return: -130.62925720214844
global_steps: 34865152,  episode_return: -140.220458984375
global_steps: 35127296,  episode_return: -115.860107421875
global_steps: 35389440,  episode_return: -119.47993469238281
global_steps: 35651584,  episode_return: -124.38340759277344
global_steps: 35913728,  episode_return: -134.277587890625
global_steps: 36175872,  episode_return: -151.97267150878906
global_steps: 36438016,  episode_return: -137.14207458496094
global_steps: 36700160,  episode_return: -121.23114776611328
global_steps: 36962304,  episode_return: -141.54649353027344
global_steps: 37224448,  episode_return: -151.57957458496094
global_steps: 37486592,  episode_return: -132.69102478027344
global_steps: 37748736,  episode_return: -147.92391967773438
global_steps: 38010880,  episode_return: -118.19192504882812
global_steps: 38273024,  episode_return: -107.89476013183594
global_steps: 38535168,  episode_return: -125.9493637084961
global_steps: 38797312,  episode_return: -127.52262115478516
global_steps: 39059456,  episode_return: -139.20114135742188
global_steps: 39321600,  episode_return: -114.87944793701172
global_steps: 39583744,  episode_return: -133.77249145507812
global_steps: 39845888,  episode_return: -125.59016418457031
global_steps: 40108032,  episode_return: -103.66265869140625
global_steps: 40370176,  episode_return: -127.21768951416016
global_steps: 40632320,  episode_return: -120.30870819091797
global_steps: 40894464,  episode_return: -125.98345184326172
global_steps: 41156608,  episode_return: -164.22457885742188
global_steps: 41418752,  episode_return: -165.0564422607422
global_steps: 41680896,  episode_return: -157.75027465820312
global_steps: 41943040,  episode_return: -148.37879943847656
global_steps: 42205184,  episode_return: -136.95611572265625
global_steps: 42467328,  episode_return: -177.81768798828125
global_steps: 42729472,  episode_return: -138.4597625732422
global_steps: 42991616,  episode_return: -124.99711608886719
global_steps: 43253760,  episode_return: -123.55046844482422
global_steps: 43515904,  episode_return: -125.44642639160156
global_steps: 43778048,  episode_return: -126.59012603759766
global_steps: 44040192,  episode_return: -118.95976257324219
global_steps: 44302336,  episode_return: -130.44015502929688
global_steps: 44564480,  episode_return: -158.96058654785156
global_steps: 44826624,  episode_return: -118.0152359008789
global_steps: 45088768,  episode_return: -133.5186309814453
global_steps: 45350912,  episode_return: -140.76332092285156
global_steps: 45613056,  episode_return: -140.52696228027344
global_steps: 45875200,  episode_return: -136.77439880371094
global_steps: 46137344,  episode_return: -110.94499206542969
global_steps: 46399488,  episode_return: -115.65289306640625
global_steps: 46661632,  episode_return: -112.67906188964844
global_steps: 46923776,  episode_return: -132.2776336669922
global_steps: 47185920,  episode_return: -120.35225677490234
global_steps: 47448064,  episode_return: -151.28533935546875
global_steps: 47710208,  episode_return: -117.6904296875
global_steps: 47972352,  episode_return: -143.2601318359375
global_steps: 48234496,  episode_return: -142.9271697998047
global_steps: 48496640,  episode_return: -149.7685546875
global_steps: 48758784,  episode_return: -129.24273681640625
global_steps: 49020928,  episode_return: -134.50653076171875
global_steps: 49283072,  episode_return: -133.42774963378906
global_steps: 49545216,  episode_return: -114.25068664550781
global_steps: 49807360,  episode_return: -169.95213317871094
Training finished in 2400.93s
best_model saved.
wandb: Adding directory to artifact (/home/zhixin/jaxrl-learning/wandb/run-20260108_205046-9ckcqdur/files/ckpts/best_model)... Done. 0.0s
wandb: uploading artifact Ant-brax__ddpg__0__20260108_205045-best-model; updating run metadata
wandb: uploading artifact Ant-brax__ddpg__0__20260108_205045-best-model; uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb: uploading artifact Ant-brax__ddpg__0__20260108_205045-best-model
wandb: uploading summary, console lines 233-235
wandb: 
wandb: Run history:
wandb:    charts/episodic_length â–â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–„â–†â–†â–†â–‡â–ˆâ–‡â–‡â–‡â–‡â–†â–‡â–†â–†â–†
wandb:    charts/episodic_return â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–…â–„â–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–‡
wandb:       charts/global_steps â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: eval/best_episodic_return â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:      eval/episodic_length â–ƒâ–ˆâ–‚â–…â–ƒâ–‚â–‚â–‚â–„â–‚â–â–â–‚â–â–â–â–‚â–„â–ƒâ–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–
wandb:      eval/episodic_return â–‡â–‚â–‡â–ˆâ–…â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–…â–â–‚â–…â–…â–…â–…â–…â–†â–†â–†â–†â–…â–†â–†â–†â–…â–†â–†â–†â–†â–†â–†â–†
wandb:         losses/actor_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–†â–…â–…â–…â–…â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–
wandb:        losses/critic_loss â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–‡â–„â–„â–†â–‡â–…â–ˆâ–†â–†â–ˆâ–‡
wandb: 
wandb: Run summary:
wandb:    charts/episodic_length 203.39453
wandb:    charts/episodic_return 587.67529
wandb:       charts/global_steps 49806336
wandb: eval/best_episodic_return 227.3248
wandb:      eval/episodic_length 132.22441
wandb:      eval/episodic_return -169.95213
wandb:         losses/actor_loss -97.17485
wandb:        losses/critic_loss 79.04676
wandb: 
wandb: ğŸš€ View run Ant-brax__ddpg__0__20260108_205045 at: https://wandb.ai/zhixin/jaxrl/runs/9ckcqdur
wandb: â­ï¸ View project at: https://wandb.ai/zhixin/jaxrl
wandb: Synced 8 W&B file(s), 0 media file(s), 12 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260108_205046-9ckcqdur/logs
{'best episodic return': 227.32479858398438,
 'average episodic return': -128.4609832763672,
 'latest episodic return': -169.95213317871094}
wandb: Currently logged in as: zhixin to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run 9cdsjqbe
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /home/zhixin/jaxrl-learning/wandb/run-20260108_220518-9cdsjqbe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run Ant-brax__ddpg__0__20260108_220517
wandb: â­ï¸ View project at https://wandb.ai/zhixin/jaxrl
wandb: ğŸš€ View run at https://wandb.ai/zhixin/jaxrl/runs/9cdsjqbe
Warp DeprecationWarning: The namespace `warp.context` will soon be removed from the public API. It can still be accessed from `warp._src.context` but might be changed or removed without notice.
Warp DeprecationWarning: The symbol `warp.context.Module` will soon be removed from the public API. Use `warp.Module` instead.
Warp DeprecationWarning: The symbol `warp.context.assert_conditional_graph_support` will soon be removed from the public API. It can still be accessed from `warp._src.context.assert_conditional_graph_support` but might be changed or removed without notice.
Warp DeprecationWarning: The symbol `warp.context.get_module` will soon be removed from the public API. Use `warp.get_module` instead.
Warp DeprecationWarning: The namespace `warp.math` will soon be removed from the public API. It can still be accessed from `warp._src.math` but might be changed or removed without notice.
config:
DDPGConfig(seed=0,
           exp_name='ddpg',
           project_name='jaxrl',
           env_name='Ant-brax',
           norm_obs=True,
           total_timesteps=50000000,
           features=(128, 64),
           lr_critic=0.001,
           lr_actor=0.001,
           gamma=0.99,
           tau=0.001,
           target_update_interval=1,
           exploration_type='normal_noise',
           exploration_noise=0.2,
           exploration_noise_end=0.0,
           exploration_noise_decay=False,
           ou_theta=0.15,
           epsilon_start=1.0,
           epsilon_end=0.05,
           exploration_fraction=0.9,
           num_env=1024,
           train_interval=1024,
           train_batch_size=256,
           buffer_size=1000000.0,
           learning_start=100000.0,
           eval_interval=262144,
           eval_num_steps=2000,
           eval_num_env=1024,
           log_interval=262144,
           wandb=True,
           save_model=True,
           run_name='Ant-brax__ddpg__0__20260108_220517',
           ckpt_path='/home/zhixin/jaxrl-learning/ckpts/',
           silent=False,
           vmap_run=False)
start training...
global_steps: 262144,  episode_return: -878.0020141601562
best_model saved.
global_steps: 524288,  episode_return: -190.05624389648438
best_model saved.
global_steps: 786432,  episode_return: -20.949697494506836
best_model saved.
global_steps: 1048576,  episode_return: 9.840147972106934
best_model saved.
global_steps: 1310720,  episode_return: 53.96962356567383
best_model saved.
global_steps: 1572864,  episode_return: 64.791259765625
best_model saved.
global_steps: 1835008,  episode_return: 227.65728759765625
best_model saved.
global_steps: 2097152,  episode_return: 335.4322509765625
best_model saved.
global_steps: 2359296,  episode_return: 293.0481872558594
global_steps: 2621440,  episode_return: 200.73898315429688
global_steps: 2883584,  episode_return: 411.4986877441406
best_model saved.
global_steps: 3145728,  episode_return: 720.0181274414062
best_model saved.
global_steps: 3407872,  episode_return: 209.32266235351562
global_steps: 3670016,  episode_return: 666.7948608398438
global_steps: 3932160,  episode_return: 403.1912536621094
global_steps: 4194304,  episode_return: 222.13876342773438
global_steps: 4456448,  episode_return: 398.1159973144531
global_steps: 4718592,  episode_return: 537.966796875
E0108 22:09:44.609798 2018725 pjrt_stream_executor_client.cc:2974] Execution of replica 0 failed: INTERNAL: CpuCallback error calling callback: Traceback (most recent call last):
  File "/home/zhixin/jaxrl-learning/jaxrl_learning/algos/ddpg.py", line 458, in <module>
  File "/home/zhixin/jaxrl-learning/jaxrl_learning/algos/ddpg.py", line 432, in main
  File "/home/zhixin/jaxrl-learning/.venv/lib/python3.12/site-packages/jax/_src/traceback_util.py", line 180, in reraise_with_filtered_traceback
  File "/home/zhixin/jaxrl-learning/.venv/lib/python3.12/site-packages/jax/_src/pjit.py", line 263, in cache_miss
  File "/home/zhixin/jaxrl-learning/.venv/lib/python3.12/site-packages/jax/_src/pjit.py", line 146, in _python_pjit_helper
  File "/home/zhixin/jaxrl-learning/.venv/lib/python3.12/site-packages/jax/_src/pjit.py", line 1622, in _pjit_call_impl_python
  File "/home/zhixin/jaxrl-learning/.venv/lib/python3.12/site-packages/jax/_src/profiler.py", line 359, in wrapper
  File "/home/zhixin/jaxrl-learning/.venv/lib/python3.12/site-packages/jax/_src/interpreters/pxla.py", line 1371, in __call__
  File "/home/zhixin/jaxrl-learning/.venv/lib/python3.12/site-packages/jax/_src/callback.py", line 783, in _wrapped_callback
KeyboardInterrupt: 
Traceback (most recent call last):
  File "/home/zhixin/jaxrl-learning/jaxrl_learning/algos/ddpg.py", line 458, in <module>
    metrics, *_ = main(config)
                  ^^^^^^^^^^^^
  File "/home/zhixin/jaxrl-learning/jaxrl_learning/algos/ddpg.py", line 432, in main
    metrics, actor_train_state, critic_train_state, best_model_params = train(config, key)
                                                                        ^^^^^^^^^^^^^^^^^^
jax.errors.JaxRuntimeError: INTERNAL: CpuCallback error calling callback: Traceback (most recent call last):
  File "/home/zhixin/jaxrl-learning/jaxrl_learning/algos/ddpg.py", line 458, in <module>
  File "/home/zhixin/jaxrl-learning/jaxrl_learning/algos/ddpg.py", line 432, in main
  File "/home/zhixin/jaxrl-learning/.venv/lib/python3.12/site-packages/jax/_src/traceback_util.py", line 180, in reraise_with_filtered_traceback
  File "/home/zhixin/jaxrl-learning/.venv/lib/python3.12/site-packages/jax/_src/pjit.py", line 263, in cache_miss
  File "/home/zhixin/jaxrl-learning/.venv/lib/python3.12/site-packages/jax/_src/pjit.py", line 146, in _python_pjit_helper
  File "/home/zhixin/jaxrl-learning/.venv/lib/python3.12/site-packages/jax/_src/pjit.py", line 1622, in _pjit_call_impl_python
  File "/home/zhixin/jaxrl-learning/.venv/lib/python3.12/site-packages/jax/_src/profiler.py", line 359, in wrapper
  File "/home/zhixin/jaxrl-learning/.venv/lib/python3.12/site-packages/jax/_src/interpreters/pxla.py", line 1371, in __call__
  File "/home/zhixin/jaxrl-learning/.venv/lib/python3.12/site-packages/jax/_src/callback.py", line 783, in _wrapped_callback
KeyboardInterrupt: 
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
[1;34mwandb[0m: 
[1;34mwandb[0m: ğŸš€ View run [33mAnt-brax__ddpg__0__20260108_220517[0m at: [34m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20260108_220518-9cdsjqbe/logs[0m
